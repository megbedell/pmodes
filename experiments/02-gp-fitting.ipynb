{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import celerite as celery\n",
    "import exoplanet as xo\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = '/Users/mbedell/python/pmodes/experiments/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from exoplanet.gp import terms, GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try fitting a GP to a short timeseries of single-mode RV oscillations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.genfromtxt(data_dir+'sim_oneyear_onemode.csv', names=True, dtype=None, delimiter=',')\n",
    "ts_onemode = np.copy(d['ts'])\n",
    "rvs_onemode = np.copy(d['rvs'])\n",
    "xs_onemode = np.copy(d['xs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_onemode/86400., rvs_onemode, 'k.')\n",
    "plt.xlim([10.49,10.51]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (ts_onemode > 10.49 * 86400) & (ts_onemode < 10.51 * 86400)\n",
    "t = ts_onemode[inds]\n",
    "y = rvs_onemode[inds]\n",
    "yerr = np.zeros_like(y) + 0.01 # 1 cm/s homogeneous error - made up!\n",
    "t_grid = np.linspace(t[0], t[-1], 1000)\n",
    "with pm.Model() as model:\n",
    "\n",
    "    logS0 = pm.Normal(\"logS0\", mu=0.0, sd=15.0, testval=np.log(np.var(rvs_onemode)))\n",
    "    logw0 = pm.Normal(\"logw0\", mu=-3.9, sd=2.0)\n",
    "    logQ = pm.Normal(\"logQ\", mu=8.1, sd=2.0)\n",
    "\n",
    "    # Set up the kernel and GP\n",
    "    kernel = terms.SHOTerm(log_S0=logS0, log_w0=logw0, log_Q=logQ)\n",
    "    gp = GP(kernel, t, yerr ** 2)\n",
    "\n",
    "    # Add a custom \"potential\" (log probability function) with the GP likelihood\n",
    "    pm.Potential(\"gp\", gp.log_likelihood(y))\n",
    "\n",
    "with model:\n",
    "    map_soln = xo.optimize(start=model.test_point)\n",
    "    mu, var = xo.eval_in_model(gp.predict(t_grid, return_var=True), map_soln)\n",
    "    y_pred = xo.eval_in_model(gp.predict(t), map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(14,6), sharex=True, \n",
    "                              gridspec_kw={'height_ratios':[3,1], 'hspace':0.1})\n",
    "ax1.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0, label=\"data\")\n",
    "\n",
    "# Plot the prediction and the 1-sigma uncertainty\n",
    "sd = np.sqrt(var)\n",
    "art = ax1.fill_between(t_grid, mu + sd, mu - sd, color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "ax1.plot(t_grid, mu, color=\"C1\", label=\"prediction\")\n",
    "\n",
    "ax2.errorbar(t, y - y_pred, yerr=yerr, fmt=\".k\", capsize=0, label=\"resids\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't quite what we expected - our calculation from `harmonic-oscillator.ipynb` was:\n",
    "```\n",
    "log_S0: -9.33721059\n",
    "log_Q: 8.13423472\n",
    "log_omega0: -3.92565541\n",
    "```\n",
    "BUT we do have an amplitudes issue when actually generating RVs from a GP with the above kernel and comparing to the RVs that we're using here, so maybe our expected logS0 is incorrect anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with multi-mode RVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.genfromtxt(data_dir+'sim_oneyear.csv', names=True, dtype=None, delimiter=',')\n",
    "ts_multimode = np.copy(d['ts'])\n",
    "rvs_multimode = np.copy(d['rvs'])\n",
    "xs_multimode = np.copy(d['xs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_multimode/86400., rvs_multimode, 'k.')\n",
    "plt.xlim([10.49,10.51]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (ts_multimode > 10.49 * 86400) & (ts_multimode < 10.51 * 86400)\n",
    "t = ts_multimode[inds]\n",
    "y = rvs_multimode[inds]\n",
    "yerr = np.zeros_like(y) + 0.01 # 1 cm/s homogeneous error - made up!\n",
    "t_grid = np.linspace(t[0], t[-1], 1000)\n",
    "with pm.Model() as model:\n",
    "\n",
    "    logS0 = pm.Normal(\"logS0\", mu=0.0, sd=15.0, testval=np.log(np.var(rvs_onemode)))\n",
    "    logw0 = pm.Normal(\"logw0\", mu=-3.9, sd=2.0)\n",
    "    logQ = pm.Normal(\"logQ\", mu=8.1, sd=2.0)\n",
    "\n",
    "    # Set up the kernel and GP\n",
    "    kernel = terms.SHOTerm(log_S0=logS0, log_w0=logw0, log_Q=logQ)\n",
    "    gp = GP(kernel, t, yerr ** 2)\n",
    "\n",
    "    # Add a custom \"potential\" (log probability function) with the GP likelihood\n",
    "    pm.Potential(\"gp\", gp.log_likelihood(y))\n",
    "\n",
    "with model:\n",
    "    map_soln = xo.optimize(start=model.test_point)\n",
    "    mu, var = xo.eval_in_model(gp.predict(t_grid, return_var=True), map_soln)\n",
    "    y_pred = xo.eval_in_model(gp.predict(t), map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(14,6), sharex=True, \n",
    "                              gridspec_kw={'height_ratios':[3,1], 'hspace':0.1})\n",
    "ax1.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0, label=\"data\")\n",
    "\n",
    "# Plot the prediction and the 1-sigma uncertainty\n",
    "sd = np.sqrt(var)\n",
    "art = ax1.fill_between(t_grid, mu + sd, mu - sd, color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "ax1.plot(t_grid, mu, color=\"C1\", label=\"prediction\")\n",
    "\n",
    "ax2.errorbar(t, y - y_pred, yerr=yerr, fmt=\".k\", capsize=0, label=\"resids\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also an excellent fit, even though we only used one mode. Maybe a single DDHO is a good approximation over short timescales - let's try a longer stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "ax.plot(ts_multimode/86400., rvs_multimode, 'k.')\n",
    "ax.set_xlim([10.2,10.8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (ts_multimode > 10.2 * 86400) & (ts_multimode < 10.8 * 86400)\n",
    "t = ts_multimode[inds]\n",
    "y = rvs_multimode[inds]\n",
    "yerr = np.zeros_like(y) + 0.01 # 1 cm/s homogeneous error - made up!\n",
    "t_grid = np.linspace(t[0], t[-1], 1000)\n",
    "with pm.Model() as model:\n",
    "\n",
    "    logS0 = pm.Normal(\"logS0\", mu=0.0, sd=15.0, testval=np.log(np.var(rvs_onemode)))\n",
    "    logw0 = pm.Normal(\"logw0\", mu=-3.9, sd=2.0)\n",
    "    logQ = pm.Normal(\"logQ\", mu=8.1, sd=2.0)\n",
    "\n",
    "    # Set up the kernel and GP\n",
    "    kernel = terms.SHOTerm(log_S0=logS0, log_w0=logw0, log_Q=logQ)\n",
    "    gp = GP(kernel, t, yerr ** 2)\n",
    "\n",
    "    # Add a custom \"potential\" (log probability function) with the GP likelihood\n",
    "    pm.Potential(\"gp\", gp.log_likelihood(y))\n",
    "\n",
    "with model:\n",
    "    map_soln = xo.optimize(start=model.test_point)\n",
    "    mu, var = xo.eval_in_model(gp.predict(t_grid, return_var=True), map_soln)\n",
    "    y_pred = xo.eval_in_model(gp.predict(t), map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(14,6), sharex=True, \n",
    "                              gridspec_kw={'height_ratios':[3,1], 'hspace':0.1})\n",
    "ax1.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0, label=\"data\")\n",
    "\n",
    "# Plot the prediction and the 1-sigma uncertainty\n",
    "sd = np.sqrt(var)\n",
    "art = ax1.fill_between(t_grid, mu + sd, mu - sd, color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "ax1.plot(t_grid, mu, color=\"C1\", label=\"prediction\")\n",
    "\n",
    "ax2.errorbar(t, y - y_pred, yerr=yerr, fmt=\".k\", capsize=0, label=\"resids\", alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do next:\n",
    "- figure out why this works so well & whether we actually need the entire comb of modes\n",
    "- try sparser data such that coherence is lost between sets of exposures\n",
    "- simulate longer exposure times\n",
    "- model longer exposure RVs as an integral of the p-mode GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-mode RVs, sparser data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inds = np.arange(len(ts_multimode))[(ts_multimode > 10.2 * 86400) & (ts_multimode < 10.8 * 86400)]\n",
    "inds = np.random.choice(all_inds, size=200, replace=False)\n",
    "inds.sort()\n",
    "t = ts_multimode[inds]\n",
    "y = rvs_multimode[inds]\n",
    "yerr = np.zeros_like(y) + 0.01 # 1 cm/s homogeneous error - made up!\n",
    "t_grid = np.linspace(t[0], t[-1], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    logS0 = pm.Normal(\"logS0\", mu=0.0, sd=15.0, testval=np.log(np.var(rvs_onemode)))\n",
    "    logw0 = pm.Normal(\"logw0\", mu=-3.9, sd=2.0)\n",
    "    logQ = pm.Normal(\"logQ\", mu=8.1, sd=2.0)\n",
    "\n",
    "    # Set up the kernel and GP\n",
    "    kernel = terms.SHOTerm(log_S0=logS0, log_w0=logw0, log_Q=logQ)\n",
    "    gp = GP(kernel, t, yerr ** 2)\n",
    "\n",
    "    # Add a custom \"potential\" (log probability function) with the GP likelihood\n",
    "    pm.Potential(\"gp\", gp.log_likelihood(y))\n",
    "\n",
    "with model:\n",
    "    map_soln = xo.optimize(start=model.test_point)\n",
    "    mu, var = xo.eval_in_model(gp.predict(t_grid, return_var=True), map_soln)\n",
    "    y_pred = xo.eval_in_model(gp.predict(t), map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(14,6), sharex=True, \n",
    "                              gridspec_kw={'height_ratios':[3,1], 'hspace':0.1})\n",
    "ax1.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0, label=\"data\")\n",
    "\n",
    "# Plot the prediction and the 1-sigma uncertainty\n",
    "sd = np.sqrt(var)\n",
    "art = ax1.fill_between(t_grid, mu + sd, mu - sd, color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "ax1.plot(t_grid, mu, color=\"C1\", label=\"prediction\")\n",
    "\n",
    "ax2.errorbar(t, y - y_pred, yerr=yerr, fmt=\".k\", capsize=0, label=\"resids\", alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(14,4))\n",
    "                              \n",
    "art = ax1.fill_between(t_grid, mu + sd, mu - sd, color=\"C1\", alpha=0.3)\n",
    "art.set_edgecolor(\"none\")\n",
    "ax1.plot(t_grid, mu, color=\"C1\", label=\"prediction\")\n",
    "\n",
    "ax1.plot(ts_multimode, rvs_multimode, \".k\")\n",
    "ax1.errorbar(t, y, yerr=yerr, fmt=\".r\", capsize=0, label=\"data\")\n",
    "\n",
    "ax1.set_xlim([890000, 895000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer-integration observations\n",
    "\n",
    "Now that we're satisfied the GP works in general, let's test how it performs for observations that are integrated over longer times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_exposure(ts, rvs, start_time, exp_time):\n",
    "    pad = 100. # seconds - ARBITRARY\n",
    "    smaller_inds = (ts > (start_time - pad)) & (ts < (start_time + exp_time + pad))    \n",
    "    interp = interp1d(ts[smaller_inds], rvs[smaller_inds], kind='cubic')\n",
    "    tiny = 0.1 # 100 ms\n",
    "    fine_ts = np.arange(start_time, start_time+exp_time, tiny) # fine grid\n",
    "    fine_rvs = interp(fine_ts)\n",
    "    return np.sum(fine_rvs)/len(fine_rvs) # ASSUMES EVEN WEIGHTING - technically incorrect for last point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = (ts_multimode > 10.2 * 86400) & (ts_multimode < 10.8 * 86400)\n",
    "exp_time = 30. #seconds\n",
    "start_ts = ts[inds]\n",
    "mid_rvs = np.array([simulate_exposures(ts, rvs, tt, exp_time) for tt in start_ts])\n",
    "mid_ts = start_ts + exp_time/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mid_ts, mid_rvs, 'k.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
